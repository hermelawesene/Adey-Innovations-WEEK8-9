{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 14625,
     "status": "ok",
     "timestamp": 1730193827974,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "sAS7A7s9Pv65"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "# !pip install scikit-learn keras tensorflow\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Conv2D, Flatten\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11865,
     "status": "ok",
     "timestamp": 1730193839837,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "0FlJFRZzP1Xl",
    "outputId": "f994d30d-3e58-4d16-a9a4-e155a361dafc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creditcard Train: (226980, 30) (226980,)\n",
      "Creditcard Test: (56746, 30) (56746,)\n"
     ]
    }
   ],
   "source": [
    "file_path_credit = 'creditcard_data_featured.csv'\n",
    "creditcard_data = pd.read_csv(file_path_credit)\n",
    "\n",
    "# Feature and Target Separation\n",
    "# For creditcard dataset\n",
    "X_creditcard = creditcard_data.drop('Class', axis=1)  # Features\n",
    "y_creditcard = creditcard_data['Class']               # Target\n",
    "\n",
    "# Train-Test Split (80% train, 20% test by default)\n",
    "X_creditcard_train, X_creditcard_test, y_creditcard_train, y_creditcard_test = train_test_split(\n",
    "    X_creditcard, y_creditcard, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print shapes of the resulting datasets\n",
    "print(\"Creditcard Train:\", X_creditcard_train.shape, y_creditcard_train.shape)\n",
    "print(\"Creditcard Test:\", X_creditcard_test.shape, y_creditcard_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1730193839837,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "GyIi4xhBln_X"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 2644,
     "status": "ok",
     "timestamp": 1730193993000,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "xnJHTw-Olrb2"
   },
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store model performances\n",
    "model_performance = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "log_model = LogisticRegression(max_iter=1000)\n",
    "accuracy, report = evaluate_model(log_model, X_creditcard_train, y_creditcard_train, X_creditcard_test, y_creditcard_test)\n",
    "model_performance['Logistic Regression'] = (accuracy, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 61685,
     "status": "ok",
     "timestamp": 1730194085147,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "8MIb1k72luHB"
   },
   "outputs": [],
   "source": [
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "accuracy, report = evaluate_model(dt_model, X_creditcard_train, y_creditcard_train, X_creditcard_test, y_creditcard_test)\n",
    "model_performance['Decision Tree'] = (accuracy, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 446297,
     "status": "ok",
     "timestamp": 1730194531440,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "pmXoqLirmaH9"
   },
   "outputs": [],
   "source": [
    "# 3. Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "accuracy, report = evaluate_model(rf_model, X_creditcard_train, y_creditcard_train, X_creditcard_test, y_creditcard_test)\n",
    "model_performance['Random Forest'] = (accuracy, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 662356,
     "status": "ok",
     "timestamp": 1730195193790,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "HvAMdiZImnbx"
   },
   "outputs": [],
   "source": [
    "# 4. Gradient Boosting\n",
    "gb_model = GradientBoostingClassifier()\n",
    "accuracy, report = evaluate_model(gb_model, X_creditcard_train, y_creditcard_train, X_creditcard_test, y_creditcard_test)\n",
    "model_performance['Gradient Boosting'] = (accuracy, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 46214,
     "status": "ok",
     "timestamp": 1730195239997,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "cFYhLlJfmyr_"
   },
   "outputs": [],
   "source": [
    "# 5. Multi-Layer Perceptron (MLP)\n",
    "mlp_model = MLPClassifier(max_iter=1000)\n",
    "accuracy, report = evaluate_model(mlp_model, X_creditcard_train, y_creditcard_train, X_creditcard_test, y_creditcard_test)\n",
    "model_performance['Multi-Layer Perceptron'] = (accuracy, report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 164429,
     "status": "ok",
     "timestamp": 1730195404422,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "Q3ymftrSnCZw",
    "outputId": "e30245da-90a9-43e7-b041-492cd96734ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2289f9ae990>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Convolutional Neural Network (CNN)\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Flatten, Dense\n",
    "# Reshape the data for CNN (assuming a single feature input)\n",
    "X_creditcard_train_cnn = X_creditcard_train.values.reshape(X_creditcard_train.shape[0], X_creditcard_train.shape[1], 1)\n",
    "X_creditcard_test_cnn = X_creditcard_test.values.reshape(X_creditcard_test.shape[0], X_creditcard_test.shape[1], 1)\n",
    "\n",
    "# Adjust the kernel size to be smaller or equal to the input dimensions\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(32, 3, activation='relu', input_shape=(X_creditcard_train_cnn.shape[1], X_creditcard_train_cnn.shape[2])), # Changed to Conv1D and adjusted kernel size\n",
    "    Flatten(),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_creditcard_train_cnn, y_creditcard_train, epochs=10, batch_size=32, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5504,
     "status": "ok",
     "timestamp": 1730195812081,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "KdVV69_5nlqa"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Before calling evaluate, ensure data types are compatible with TensorFlow:\n",
    "X_creditcard_test_cnn = X_creditcard_test_cnn.astype(np.float32)  # Convert to float32\n",
    "y_creditcard_test = tf.cast(y_creditcard_test, tf.float32)  # Use tf.cast to convert to float32\n",
    "\n",
    "# Additionally, check for and handle NaN/infinity values:\n",
    "X_creditcard_test_cnn = np.nan_to_num(X_creditcard_test_cnn)  # Replace NaN and infinity with finite values\n",
    "# For TensorFlow tensors, you can use tf.where to handle NaN/infinity\n",
    "y_creditcard_test = tf.where(tf.math.is_finite(y_creditcard_test), y_creditcard_test, 0.0) #If infinite or Nan, replace with 0\n",
    "\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(X_creditcard_test_cnn, y_creditcard_test, verbose=0)\n",
    "model_performance['Convolutional Neural Network'] = (cnn_accuracy, 'N/A')  # No report for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 226898,
     "status": "ok",
     "timestamp": 1730195631317,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "6XdxfobWomtp",
    "outputId": "fcc51f72-6f06-4e0d-cf61-9fedbbc5a989"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x228a0550b90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. Recurrent Neural Network (RNN)\n",
    "# Reshape for RNN (assumes time steps of 1)\n",
    "X_creditcard_train_rnn = X_creditcard_train.values.reshape(X_creditcard_train.shape[0], 1, X_creditcard_train.shape[1])\n",
    "X_creditcard_test_rnn = X_creditcard_test.values.reshape(X_creditcard_test.shape[0], 1, X_creditcard_test.shape[1])\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(32, input_shape=(X_creditcard_train_rnn.shape[1], X_creditcard_train_rnn.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.fit(X_creditcard_train_rnn, y_creditcard_train, epochs=10, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 3027,
     "status": "ok",
     "timestamp": 1730195815105,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "oWcs8RvWpK_J"
   },
   "outputs": [],
   "source": [
    "# Before evaluating the RNN, ensure data types are compatible with TensorFlow:\n",
    "X_creditcard_test_rnn = X_creditcard_test_rnn.astype(np.float32)  # Convert to float32\n",
    "# If y_creditcard_test was modified earlier, reset it to its original type\n",
    "# Use tf.cast for TensorFlow tensors\n",
    "y_creditcard_test = tf.cast(y_creditcard_test, tf.int64) if isinstance(y_creditcard_test, tf.Tensor) else y_creditcard_test.astype(np.int64)\n",
    "\n",
    "# Convert y_creditcard_test to a TensorFlow tensor with float32 type\n",
    "y_creditcard_test = tf.cast(y_creditcard_test, tf.float32)\n",
    "\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(X_creditcard_test_rnn, y_creditcard_test, verbose=0)\n",
    "model_performance['Recurrent Neural Network'] = (rnn_accuracy, 'N/A')  # No report for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 175266,
     "status": "ok",
     "timestamp": 1730195806579,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "gcOF1Ftopo-K"
   },
   "outputs": [],
   "source": [
    "# 8. Long Short-Term Memory (LSTM)\n",
    "# Using the same RNN model as the LSTM in this example\n",
    "\n",
    "lstm_model = Sequential([\n",
    "    LSTM(32, input_shape=(X_creditcard_train_rnn.shape[1], X_creditcard_train_rnn.shape[2])),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(X_creditcard_train_rnn, y_creditcard_train, epochs=10, batch_size=32, verbose=0)\n",
    "lstm_loss, lstm_accuracy = lstm_model.evaluate(X_creditcard_test_rnn, y_creditcard_test, verbose=0)\n",
    "model_performance['Long Short-Term Memory'] = (lstm_accuracy, 'N/A')  # No report for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1730195815105,
     "user": {
      "displayName": "hermela wesene",
      "userId": "13348420819649693129"
     },
     "user_tz": -180
    },
    "id": "kcxali0op0eW",
    "outputId": "919126b8-942a-4300-a15e-187c3e4847a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.9992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.88      0.54      0.67        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.94      0.77      0.84     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Decision Tree Accuracy: 0.9990\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.68      0.72      0.70        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.84      0.86      0.85     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Random Forest Accuracy: 0.9996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.99      0.73      0.84        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.87      0.92     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Gradient Boosting Accuracy: 0.9993\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.89      0.63      0.74        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.95      0.82      0.87     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Multi-Layer Perceptron Accuracy: 0.9995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56656\n",
      "           1       0.98      0.70      0.82        90\n",
      "\n",
      "    accuracy                           1.00     56746\n",
      "   macro avg       0.99      0.85      0.91     56746\n",
      "weighted avg       1.00      1.00      1.00     56746\n",
      "\n",
      "Convolutional Neural Network Accuracy: 0.9995\n",
      "Recurrent Neural Network Accuracy: 0.9995\n",
      "Long Short-Term Memory Accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Print model performance results\n",
    "for model, (accuracy, report) in model_performance.items():\n",
    "    print(f\"{model} Accuracy: {accuracy:.4f}\")\n",
    "    if report != 'N/A':\n",
    "        print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ltEGs308ydI7"
   },
   "source": [
    "# Model Interpretation for creditcard\n",
    "\n",
    "## 1. Logistic Regression\n",
    "- **Accuracy**: 0.9992\n",
    "- **Interpretation**: This model demonstrates high accuracy overall but struggles significantly with detecting fraud (class 1). The precision for fraud detection is 0.88, which indicates that when it predicts fraud, it is correct 88% of the time. However, the recall is only 0.54, meaning it identifies just 54% of actual fraud cases. The F1-score of 0.67 shows a lack of balance between precision and recall, suggesting that the model is biased towards predicting non-fraud cases due to the class imbalance.\n",
    "\n",
    "## 2. Decision Tree\n",
    "- **Accuracy**: 0.9991\n",
    "- **Interpretation**: The Decision Tree model has similar accuracy to Logistic Regression but performs slightly better in detecting fraud. It achieves a precision of 0.69 and a recall of 0.73 for fraud cases, indicating a better ability to identify actual frauds. The F1-score of 0.71 suggests that while it can capture some fraudulent transactions, there is still significant room for improvement, especially in reducing false positives.\n",
    "\n",
    "## 3. Random Forest\n",
    "- **Accuracy**: 0.9995\n",
    "- **Interpretation**: The Random Forest model exhibits the highest accuracy and shows a strong capability in detecting fraud. It achieves a precision of 0.96, meaning that when it predicts fraud, it is highly reliable. The recall for fraud cases is 0.73, indicating that it correctly identifies 73% of actual frauds. The F1-score of 0.83 signifies a good balance between precision and recall, making it a robust model for fraud detection.\n",
    "\n",
    "## 4. Gradient Boosting\n",
    "- **Accuracy**: 0.9993\n",
    "- **Interpretation**: Similar to Random Forest, Gradient Boosting also demonstrates high accuracy. It has a precision of 0.89 and a recall of 0.63 for fraud detection. While it is reasonably good at identifying fraud cases, the lower recall indicates it misses a larger portion of actual frauds compared to Random Forest. The F1-score of 0.74 shows it balances precision and recall but suggests room for enhancement in fraud detection capabilities.\n",
    "\n",
    "## 5. Multi-Layer Perceptron (MLP)\n",
    "- **Accuracy**: 0.9995\n",
    "- **Interpretation**: The MLP model achieves similar accuracy to Random Forest and Gradient Boosting. It has a precision of 0.87 and a recall of 0.80 for fraud cases, indicating a strong performance in identifying fraud. The F1-score of 0.83 suggests that the model maintains a good balance between precision and recall, indicating it can effectively detect fraudulent transactions while managing false positives.\n",
    "\n",
    "## 6. Long Short-Term Memory (LSTM)\n",
    "- **Accuracy**: 0.9995\n",
    "- **Interpretation**: The LSTM model shows high accuracy but lacks detailed metrics in the report. Generally, LSTMs are effective for sequential data and could capture temporal patterns in fraud, but further metrics are needed to evaluate its precision and recall accurately.\n",
    "\n",
    "## 7. Convolutional Neural Network (CNN)\n",
    "- **Accuracy**: 0.9994\n",
    "- **Interpretation**: Similar to LSTM, the CNN shows high accuracy but does not provide detailed performance metrics. CNNs are typically used for image data but can also be adapted for structured data. Without specific precision and recall values, the model's performance in detecting fraud remains unclear.\n",
    "\n",
    "## 8. Recurrent Neural Network (RNN)\n",
    "- **Accuracy**: 0.9995\n",
    "- **Interpretation**: Like the LSTM, the RNN achieves high accuracy without detailed evaluation metrics. RNNs are designed for sequential data analysis and may be useful in identifying patterns over time, but again, further metrics are needed to fully interpret its effectiveness in fraud detection.\n",
    "\n",
    "# Summary\n",
    "Overall, the Random Forest model stands out for its high precision and reasonable recall, making it the most effective model for fraud detection among those evaluated. Logistic Regression, while achieving high accuracy, shows significant weaknesses in identifying fraud cases due to class imbalance. Further improvements can be made across all models, particularly in recall for fraud detection, to enhance their effectiveness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkazJeZTzwRx"
   },
   "source": [
    "# Model Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import shap\n",
    "import pandas as pd\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit as sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explainability(model, X_train, X_test):\n",
    "    \"\"\"\n",
    "    Generates SHAP explanations for a given model and data.\n",
    "\n",
    "    Parameters:\n",
    "        model: The trained model to explain.\n",
    "        X_train: The training data used to train the model.\n",
    "        X_test: The test data to explain.\n",
    "\n",
    "    Returns:\n",
    "        None. Displays SHAP plots.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert input data to numeric types\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "\n",
    "    # Create a SHAP explainer\n",
    "    masker = shap.maskers.Independent(X_train)\n",
    "    shap_explainer = shap.Explainer(model.predict, masker)\n",
    "    \n",
    "    # Get SHAP values for the test data\n",
    "    shap_values = shap_explainer(X_test)\n",
    "    \n",
    "    # SHAP summary plot\n",
    "    shap.plots.beeswarm(shap_values[:, :, 0])\n",
    "    \n",
    "    # SHAP force plot\n",
    "    shap.plots.force(shap_values[0, :, 0])\n",
    "    \n",
    "    # SHAP dependence plot\n",
    "    shap.plots.scatter(shap_values[:, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_explainability_neural(model, X_train, X_test):\n",
    "\n",
    "    # Convert input data to numeric types\n",
    "    X_train = X_train.astype(float)\n",
    "    X_test = X_test.astype(float)\n",
    "      \n",
    "\n",
    "    # Create a SHAP explainer\n",
    "    masker = shap.maskers.Independent(X_train)\n",
    "    model_proba = lambda x: sigmoid(model.predict(x))\n",
    "    shap_explainer = shap.Explainer(model_proba, masker, algorithm='permutation', nsamples=100, verbose=0)\n",
    "    \n",
    "    # Get SHAP values for the test data\n",
    "    shap_values = shap_explainer(X_test)\n",
    "    \n",
    "    # SHAP summary plot\n",
    "    shap.plots.beeswarm(shap_values)\n",
    "    \n",
    "    # SHAP force plot\n",
    "    shap.plots.force(shap_values[0,:])\n",
    "    \n",
    "    # SHAP dependence plot\n",
    "    shap.plots.scatter(shap_values[:, \"feature_name\"],  ylabel=\"SHAP value\\n(higher means more likely to fraud)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lime_explainability(model, X_train, X_test):\n",
    "    # Convert X_train to a pandas DataFrame\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    \n",
    "    # Create a LIME explainer\n",
    "    lime_explainer = LimeTabularExplainer(X_train_df.values, feature_names=X_train_df.columns, class_names=[\"Not Fraud\", \"Fraud\"], discretize_continuous=True)\n",
    "    \n",
    "    # Get LIME explanations for the test data\n",
    "    lime_explanation = lime_explainer.explain_instance(X_test.iloc[0].values, model.predict, num_features=5)    \n",
    "    # LIME feature importance plot\n",
    "    lime_explanation.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explaining Logistic Regression model with SHAP...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 56747it [23:31, 39.97it/s]                              \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Explain the evaluated models\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplaining Logistic Regression model with SHAP...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mshap_explainability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_creditcard_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_creditcard_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 26\u001b[0m, in \u001b[0;36mshap_explainability\u001b[1;34m(model, X_train, X_test)\u001b[0m\n\u001b[0;32m     23\u001b[0m shap_values \u001b[38;5;241m=\u001b[39m shap_explainer(X_test)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# SHAP summary plot\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m shap\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mbeeswarm(\u001b[43mshap_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# SHAP force plot\u001b[39;00m\n\u001b[0;32m     29\u001b[0m shap\u001b[38;5;241m.\u001b[39mplots\u001b[38;5;241m.\u001b[39mforce(shap_values[\u001b[38;5;241m0\u001b[39m, :, \u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\shap\\_explanation.py:391\u001b[0m, in \u001b[0;36mExplanation.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_self \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    390\u001b[0m     new_self \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 391\u001b[0m new_self\u001b[38;5;241m.\u001b[39m_s \u001b[38;5;241m=\u001b[39m \u001b[43mnew_self\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_s\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m new_self\u001b[38;5;241m.\u001b[39mop_history\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    393\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitem__\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margs\u001b[39m\u001b[38;5;124m\"\u001b[39m: (item,),\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprev_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    396\u001b[0m })\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_self\n",
      "File \u001b[1;32mc:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\slicer\\slicer.py:103\u001b[0m, in \u001b[0;36mSlicer.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, item):\n\u001b[1;32m--> 103\u001b[0m     index_tup \u001b[38;5;241m=\u001b[39m \u001b[43munify_slice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_alias_lookup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    105\u001b[0m     new_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\slicer\\slicer_internal.py:85\u001b[0m, in \u001b[0;36munify_slice\u001b[1;34m(item, max_dim, alias_lookup)\u001b[0m\n\u001b[0;32m     83\u001b[0m item \u001b[38;5;241m=\u001b[39m _normalize_slice_key(item)\n\u001b[0;32m     84\u001b[0m index_tup \u001b[38;5;241m=\u001b[39m _normalize_subkey_types(item)\n\u001b[1;32m---> 85\u001b[0m index_tup \u001b[38;5;241m=\u001b[39m \u001b[43m_handle_newaxis_ellipses\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_tup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m alias_lookup:\n\u001b[0;32m     87\u001b[0m     index_tup \u001b[38;5;241m=\u001b[39m _handle_aliases(index_tup, alias_lookup)\n",
      "File \u001b[1;32mc:\\Users\\Hermela\\Documents\\Fraud\\.venv\\Lib\\site-packages\\slicer\\slicer_internal.py:178\u001b[0m, in \u001b[0;36m_handle_newaxis_ellipses\u001b[1;34m(index_tup, max_dim)\u001b[0m\n\u001b[0;32m    175\u001b[0m         index_list\u001b[38;5;241m.\u001b[39mappend(item)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index_list) \u001b[38;5;241m>\u001b[39m max_dim:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoo many indices for array\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index_list) \u001b[38;5;241m<\u001b[39m max_dim:\n\u001b[0;32m    180\u001b[0m     index_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Logistic Regression model with SHAP...\")\n",
    "shap_explainability(log_model, X_creditcard_train, X_creditcard_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Logistic Regression model with LIME...\")\n",
    "lime_explainability(log_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Decision Tree model with SHAP...\")\n",
    "shap_explainability(dt_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Decision Tree model with LIME...\")\n",
    "lime_explainability(dt_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Random Forest model with SHAP...\")\n",
    "shap_explainability(rf_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Random Forest model with LIME...\")\n",
    "lime_explainability(rf_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Gradient Boosting model with SHAP...\")\n",
    "shap_explainability(gb_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Gradient Boosting model with LIME...\")\n",
    "lime_explainability(gb_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Multi-Layer Perceptron (MLP) model with SHAP...\")\n",
    "shap_explainability(mlp_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Multi-Layer Perceptron (MLP) model with LIME...\")\n",
    "lime_explainability(mlp_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explain the evaluated models\n",
    "print(\"Explaining Convolutional Neural Network (CNN) model with SHAP...\")\n",
    "shap_explainability_neural(cnn_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Convolutional Neural Network (CNN) model with LIME...\")\n",
    "lime_explainability(cnn_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Convert reshaped data to float32\n",
    "X_fraud_train_reshaped = X_fraud_train_reshaped.astype('float32')\n",
    "X_fraud_test_reshaped = X_fraud_test_reshaped.astype('float32')\n",
    "\n",
    "# Use GradientExplainer or KernelExplainer for compatibility\n",
    "shap_explainer = shap.GradientExplainer(rnn_model, X_fraud_train_reshaped)\n",
    "\n",
    "# Get SHAP values\n",
    "shap_values = shap_explainer.shap_values(X_fraud_test_reshaped)\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(shap_values, X_fraud_test_reshaped, feature_names=X_fraud_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Explaining Recurrent Neural Network (RNN) model with LIME...\")\n",
    "lime_explainability(rnn_model, X_fraud_train, X_fraud_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving my models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shap\n",
    "\n",
    "# Directory to store models and SHAP visualizations\n",
    "output_dir = \"models-creditcard\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Models dictionary\n",
    "models = {\n",
    "    'dt_model': dt_model,\n",
    "    'rf_model': rf_model,\n",
    "    'gb_model': gb_model,\n",
    "    'log_model': log_model,\n",
    "    'mlp_model': mlp_model,\n",
    "    'cnn_model': cnn_model,\n",
    "    'rnn_model': rnn_model,\n",
    "    'lstm_model': lstm_model\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dt_model to models-creditcard/dt_model.pkl\n",
      "Saved rf_model to models-creditcard/rf_model.pkl\n",
      "Saved gb_model to models-creditcard/gb_model.pkl\n",
      "Saved log_model to models-creditcard/log_model.pkl\n",
      "Saved mlp_model to models-creditcard/mlp_model.pkl\n",
      "Saved cnn_model to models-creditcard/cnn_model.pkl\n",
      "Saved rnn_model to models-creditcard/rnn_model.pkl\n",
      "Saved lstm_model to models-creditcard/lstm_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save each model as a .pkl file in the directory\n",
    "for model_name, model in models.items():\n",
    "    with open(os.path.join(output_dir, f\"{model_name}.pkl\"), 'wb') as model_file:\n",
    "        pickle.dump(model, model_file)\n",
    "        print(f\"Saved {model_name} to {output_dir}/{model_name}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP3/c5gbz9S2L/Vi/vSkkdi",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "40fc1c92854c462b9a6534c44de81042": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56a5e4cfdc024debb5a5b0178def1da3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65ddc971fdd54a67ac3ca3227a658111": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "73534d77ffb841b9b85d519fb2367b4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56a5e4cfdc024debb5a5b0178def1da3",
      "max": 56746,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9e1418d7d8474a1b8b2e34dde8d54928",
      "value": 0
     }
    },
    "9ad6db31f0f2433eb54184d594d566ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e1418d7d8474a1b8b2e34dde8d54928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ada7fef470ab4aba95aae02f8177fbba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aebd3ae7644148a98a4fac16032f2bf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ada7fef470ab4aba95aae02f8177fbba",
      "placeholder": "​",
      "style": "IPY_MODEL_9ad6db31f0f2433eb54184d594d566ff",
      "value": "  0%"
     }
    },
    "d78c3a41a1a94c2d86e4ffb20ba60c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_aebd3ae7644148a98a4fac16032f2bf9",
       "IPY_MODEL_73534d77ffb841b9b85d519fb2367b4b",
       "IPY_MODEL_f62a0b7ac94f4d03b1a6c9869d612dde"
      ],
      "layout": "IPY_MODEL_40fc1c92854c462b9a6534c44de81042"
     }
    },
    "f593d8ae68774965af5208a429846075": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f62a0b7ac94f4d03b1a6c9869d612dde": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65ddc971fdd54a67ac3ca3227a658111",
      "placeholder": "​",
      "style": "IPY_MODEL_f593d8ae68774965af5208a429846075",
      "value": " 0/56746 [00:00&lt;?, ?it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
